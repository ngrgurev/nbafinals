{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ab13a8",
   "metadata": {},
   "source": [
    "### 1. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('C:/Users/grgur/OneDrive/Desktop/finals/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8938014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg%</th>\n",
       "      <th>3p</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3p%</th>\n",
       "      <th>ft</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft%</th>\n",
       "      <th>...</th>\n",
       "      <th>tov%_max_opp_10_y</th>\n",
       "      <th>usg%_max_opp_10_y</th>\n",
       "      <th>ortg_max_opp_10_y</th>\n",
       "      <th>drtg_max_opp_10_y</th>\n",
       "      <th>total_opp_10_y</th>\n",
       "      <th>home_opp_10_y</th>\n",
       "      <th>won_10_y</th>\n",
       "      <th>season_10_y</th>\n",
       "      <th>team_opp_next_y</th>\n",
       "      <th>team_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375598</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.483373</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.730455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380294</td>\n",
       "      <td>0.273427</td>\n",
       "      <td>0.270616</td>\n",
       "      <td>0.478824</td>\n",
       "      <td>0.308654</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>SAC</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.413876</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.509501</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.827305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437212</td>\n",
       "      <td>0.124904</td>\n",
       "      <td>0.404739</td>\n",
       "      <td>0.408235</td>\n",
       "      <td>0.428846</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>SAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.455882</td>\n",
       "      <td>0.330144</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.437055</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504403</td>\n",
       "      <td>0.153273</td>\n",
       "      <td>0.344076</td>\n",
       "      <td>0.384706</td>\n",
       "      <td>0.319231</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.416268</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.419240</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.883314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467505</td>\n",
       "      <td>0.276508</td>\n",
       "      <td>0.352607</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.316346</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>GSW</td>\n",
       "      <td>TOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.186603</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.203088</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413732</td>\n",
       "      <td>0.156739</td>\n",
       "      <td>0.470142</td>\n",
       "      <td>0.391765</td>\n",
       "      <td>0.436538</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.437055</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.730455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484906</td>\n",
       "      <td>0.201284</td>\n",
       "      <td>0.375355</td>\n",
       "      <td>0.530588</td>\n",
       "      <td>0.345192</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>LAC</td>\n",
       "      <td>GSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.401914</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.263658</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.757293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468868</td>\n",
       "      <td>0.123107</td>\n",
       "      <td>0.332227</td>\n",
       "      <td>0.407059</td>\n",
       "      <td>0.370192</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.356459</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.131829</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.927655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421593</td>\n",
       "      <td>0.133504</td>\n",
       "      <td>0.345498</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>0.343269</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>BRK</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.432304</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.787631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310377</td>\n",
       "      <td>0.127086</td>\n",
       "      <td>0.312796</td>\n",
       "      <td>0.410588</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>PHI</td>\n",
       "      <td>DAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.511962</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.339667</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.722287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427568</td>\n",
       "      <td>0.258280</td>\n",
       "      <td>0.514218</td>\n",
       "      <td>0.335294</td>\n",
       "      <td>0.390385</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>PHI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 423 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mp        fg       fga       fg%        3p       3pa       3p%        ft  \\\n",
       "0  0.00  0.477273  0.500000  0.375598  0.379310  0.348485  0.483373  0.441860   \n",
       "1  0.00  0.340909  0.250000  0.413876  0.310345  0.257576  0.509501  0.511628   \n",
       "2  0.50  0.409091  0.455882  0.330144  0.482759  0.515152  0.437055  0.372093   \n",
       "3  0.25  0.545455  0.544118  0.416268  0.413793  0.454545  0.419240  0.186047   \n",
       "4  0.00  0.340909  0.558824  0.186603  0.206897  0.469697  0.203088  0.139535   \n",
       "5  0.00  0.409091  0.279412  0.476077  0.241379  0.227273  0.437055  0.441860   \n",
       "6  0.00  0.431818  0.397059  0.401914  0.137931  0.212121  0.263658  0.418605   \n",
       "7  0.25  0.500000  0.558824  0.356459  0.068966  0.212121  0.131829  0.325581   \n",
       "8  0.00  0.318182  0.323529  0.318182  0.275862  0.272727  0.432304  0.186047   \n",
       "9  0.00  0.545455  0.426471  0.511962  0.275862  0.363636  0.339667  0.348837   \n",
       "\n",
       "        fta       ft%  ...  tov%_max_opp_10_y  usg%_max_opp_10_y  \\\n",
       "0  0.396825  0.730455  ...           0.380294           0.273427   \n",
       "1  0.412698  0.827305  ...           0.437212           0.124904   \n",
       "2  0.412698  0.568261  ...           0.504403           0.153273   \n",
       "3  0.142857  0.883314  ...           0.467505           0.276508   \n",
       "4  0.111111  0.854142  ...           0.413732           0.156739   \n",
       "5  0.396825  0.730455  ...           0.484906           0.201284   \n",
       "6  0.365079  0.757293  ...           0.468868           0.123107   \n",
       "7  0.238095  0.927655  ...           0.421593           0.133504   \n",
       "8  0.158730  0.787631  ...           0.310377           0.127086   \n",
       "9  0.317460  0.722287  ...           0.427568           0.258280   \n",
       "\n",
       "   ortg_max_opp_10_y  drtg_max_opp_10_y  total_opp_10_y  home_opp_10_y  \\\n",
       "0           0.270616           0.478824        0.308654            0.6   \n",
       "1           0.404739           0.408235        0.428846            0.2   \n",
       "2           0.344076           0.384706        0.319231            0.7   \n",
       "3           0.352607           0.482353        0.316346            0.7   \n",
       "4           0.470142           0.391765        0.436538            0.6   \n",
       "5           0.375355           0.530588        0.345192            0.4   \n",
       "6           0.332227           0.407059        0.370192            0.5   \n",
       "7           0.345498           0.454118        0.343269            0.4   \n",
       "8           0.312796           0.410588        0.353846            0.5   \n",
       "9           0.514218           0.335294        0.390385            0.5   \n",
       "\n",
       "   won_10_y  season_10_y  team_opp_next_y  team_y  \n",
       "0       0.7       2016.0              SAC     TOR  \n",
       "1       0.3       2016.0              TOR     SAC  \n",
       "2       0.5       2016.0              CLE     DET  \n",
       "3       0.6       2016.0              GSW     TOR  \n",
       "4       0.1       2016.0              DEN     NOP  \n",
       "5       1.0       2016.0              LAC     GSW  \n",
       "6       0.4       2016.0              ORL     MIN  \n",
       "7       0.7       2016.0              BRK     ATL  \n",
       "8       0.6       2016.0              PHI     DAL  \n",
       "9       0.0       2016.0              DAL     PHI  \n",
       "\n",
       "[10 rows x 423 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d4b14",
   "metadata": {},
   "source": [
    "Since we've already done cleaning and adding new features part in the Ridge Regression model, we can start with the implementation of the new models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b18751",
   "metadata": {},
   "source": [
    "### 2. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8c388ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6282091917591125\n",
      "Mean Squared Error: 0.22779705158759614\n"
     ]
    }
   ],
   "source": [
    "## Linear regression model with features selected from SFS in Ridge Regression\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load the NBA dataset\n",
    "dataset = df\n",
    "\n",
    "# Select the features (X) and the target variable (y)\n",
    "X = dataset[['mp',\n",
    " 'orb',\n",
    " 'ast',\n",
    " 'tov',\n",
    " 'usg%',\n",
    " 'pf_max',\n",
    " 'trb%_max',\n",
    " 'stl%_max',\n",
    " 'mp_opp',\n",
    " 'usg%_opp',\n",
    " 'usg%_10_x',\n",
    " 'ft%_max_10_x',\n",
    " '3par_max_10_x',\n",
    " 'usg%_opp_10_x',\n",
    " 'stl_max_opp_10_x',\n",
    " 'won_10_x',\n",
    " 'next_home',\n",
    " 'drb_10_y',\n",
    " 'trb%_10_y',\n",
    " 'usg%_10_y',\n",
    " 'ft_max_10_y',\n",
    " 'efg%_max_10_y',\n",
    " 'tov%_max_10_y',\n",
    " 'trb%_opp_10_y',\n",
    " 'usg%_opp_10_y',\n",
    " 'fga_max_opp_10_y',\n",
    " 'fta_max_opp_10_y',\n",
    " 'ft%_max_opp_10_y',\n",
    " 'orb%_max_opp_10_y',\n",
    " 'won_10_y']]  \n",
    "y = dataset['target']  \n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted values to binary classes\n",
    "y_pred_classes = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65919e",
   "metadata": {},
   "source": [
    "Let's see if accuracy will improve if we let the model choose its own features, instead of SFS ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce6354be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.631378763866878\n",
      "Mean Squared Error: 0.22480815579318117\n"
     ]
    }
   ],
   "source": [
    "## IMPROVED LINEAR - putting 30 features in selector - like in SFS\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "dataset = df\n",
    "\n",
    "# Select the features (X) and the target variable (y)\n",
    "X = df.drop('target', axis=1)  \n",
    "y = df['target']\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    X[feature] = label_encoders[feature].fit_transform(X[feature])\n",
    "\n",
    "# Perform feature selection using SelectKBest and f_regression\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=30)  # Select top 30 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the Linear Regression model\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted values to binary classes\n",
    "\n",
    "y_pred_classes = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536947de",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ab59fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6269413629160063\n",
      "Mean Squared Error: 0.37305863708399367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grgur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## Logistic regression with the SFS features\n",
    "\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the NBA dataset\n",
    "dataset = df\n",
    "\n",
    "# Select the features (X) and the target variable (y)\n",
    "X = dataset[['mp',\n",
    " 'orb',\n",
    " 'ast',\n",
    " 'tov',\n",
    " 'usg%',\n",
    " 'pf_max',\n",
    " 'trb%_max',\n",
    " 'stl%_max',\n",
    " 'mp_opp',\n",
    " 'usg%_opp',\n",
    " 'usg%_10_x',\n",
    " 'ft%_max_10_x',\n",
    " '3par_max_10_x',\n",
    " 'usg%_opp_10_x',\n",
    " 'stl_max_opp_10_x',\n",
    " 'won_10_x',\n",
    " 'next_home',\n",
    " 'drb_10_y',\n",
    " 'trb%_10_y',\n",
    " 'usg%_10_y',\n",
    " 'ft_max_10_y',\n",
    " 'efg%_max_10_y',\n",
    " 'tov%_max_10_y',\n",
    " 'trb%_opp_10_y',\n",
    " 'usg%_opp_10_y',\n",
    " 'fga_max_opp_10_y',\n",
    " 'fta_max_opp_10_y',\n",
    " 'ft%_max_opp_10_y',\n",
    " 'orb%_max_opp_10_y',\n",
    " 'won_10_y']]  # Replace 'Feature1', 'Feature2', and 'Feature3' with actual feature names\n",
    "y = dataset['target']  # Replace 'Outcome' with the actual target variable name\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a76362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPROVED LOGISTICAL - 30 features in the selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9fbcf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6288431061806656\n",
      "Mean Squared Error: 0.37115689381933437\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the NBA dataset\n",
    "dataset = df\n",
    "\n",
    "# Select the features (X) and the target variable (y)\n",
    "X = df.drop('target', axis=1)  # Assuming 'Outcome' is the target variable\n",
    "y = df['target']\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    X[feature] = label_encoders[feature].fit_transform(X[feature])\n",
    "\n",
    "# Perform feature selection using SelectKBest and f_regression\n",
    "selector = SelectKBest(score_func=f_regression, k=30)  # Select top 30 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045a9c3",
   "metadata": {},
   "source": [
    "### 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b1d87c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5426307448494453\n",
      "Mean Squared Error: 0.45736925515055465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = df\n",
    "\n",
    "# Select the features (X) and the target variable (y)\n",
    "X = df.drop('target', axis=1)  \n",
    "y = df['target']\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    X[feature] = label_encoders[feature].fit_transform(X[feature])\n",
    "\n",
    "# Perform feature selection using SelectKBest and f_regression\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=3)  # Select top 3 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the Random Forest Classifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e6112fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6155309033280507\n",
      "Mean Squared Error: 0.3844690966719493\n"
     ]
    }
   ],
   "source": [
    "## IMPROVED RFC - 30 FEATURES\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = df\n",
    "\n",
    "# Select the features (X) and the target variable (y)\n",
    "X = df.drop('target', axis=1)  \n",
    "y = df['target']\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    X[feature] = label_encoders[feature].fit_transform(X[feature])\n",
    "\n",
    "# Perform feature selection using SelectKBest and f_regression\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=30)  # Select top 30 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the Random Forest Classifier model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2e985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
